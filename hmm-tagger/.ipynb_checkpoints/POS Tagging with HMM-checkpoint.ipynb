{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%aimport helpers, tests\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "from itertools import chain\n",
    "from collections import Counter, defaultdict\n",
    "from helpers import show_model, Dataset\n",
    "from pomegranate import State, HiddenMarkovModel, DiscreteDistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57340 sentences in the data\n",
      "There are 45872 sentences in the training set.\n",
      "There are 11468 sentences in the testing set\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "data = Dataset('tags-universal.txt', 'brown-universal.txt', train_test_split=0.8)\n",
    "\n",
    "print(\"There are {} sentences in the data\".format(len(data)))\n",
    "print(\"There are {} sentences in the training set.\".format(len(data.training_set)))\n",
    "print(\"There are {} sentences in the testing set\".format(len(data.testing_set)))\n",
    "\n",
    "assert len(data) == len(data.training_set) + len(data.testing_set)\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: b100-38532\n",
      "words:\n",
      "\t('Perhaps', 'it', 'was', 'right', ';', ';')\n",
      "tags:\n",
      "\t('ADV', 'PRON', 'VERB', 'ADJ', '.', '.')\n"
     ]
    }
   ],
   "source": [
    "key = 'b100-38532'\n",
    "print(\"Sentence: {}\".format(key))\n",
    "print(\"words:\\n\\t{!s}\".format(data.sentences[key].words))\n",
    "print(\"tags:\\n\\t{!s}\".format(data.sentences[key].tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 1161192 samples of 56057 unique words in the corpus.\n",
      "There are 928458 samples of 50536 unique words in the training set.\n",
      "There are 232734 samples of 25112 unique words in the testing set.\n",
      "There are 5521 words in the test set that are missing in the training set.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are a total of {} samples of {} unique words in the corpus.\"\n",
    "      .format(data.N, len(data.vocab)))\n",
    "print(\"There are {} samples of {} unique words in the training set.\"\n",
    "      .format(data.training_set.N, len(data.training_set.vocab)))\n",
    "print(\"There are {} samples of {} unique words in the testing set.\"\n",
    "      .format(data.testing_set.N, len(data.testing_set.vocab)))\n",
    "print(\"There are {} words in the test set that are missing in the training set.\"\n",
    "      .format(len(data.testing_set.vocab - data.training_set.vocab)))\n",
    "\n",
    "assert data.N == data.training_set.N + data.testing_set.N, \\\n",
    "       \"The number of training + test samples should sum to the total number of samples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: ('Mr.', 'Podger', 'had', 'thanked', 'him', 'gravely', ',', 'and', 'now', 'he', 'made', 'use', 'of', 'the', 'advice', '.')\n",
      "\n",
      "Labels 1: ('NOUN', 'NOUN', 'VERB', 'VERB', 'PRON', 'ADV', '.', 'CONJ', 'ADV', 'PRON', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN', '.')\n",
      "\n",
      "Sentence 2: ('But', 'there', 'seemed', 'to', 'be', 'some', 'difference', 'of', 'opinion', 'as', 'to', 'how', 'far', 'the', 'board', 'should', 'go', ',', 'and', 'whose', 'advice', 'it', 'should', 'follow', '.')\n",
      "\n",
      "Labels 2: ('CONJ', 'PRT', 'VERB', 'PRT', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'ADP', 'ADV', 'ADV', 'DET', 'NOUN', 'VERB', 'VERB', '.', 'CONJ', 'DET', 'NOUN', 'PRON', 'VERB', 'VERB', '.')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):    \n",
    "    print(\"Sentence {}:\".format(i + 1), data.X[i])\n",
    "    print()\n",
    "    print(\"Labels {}:\".format(i + 1), data.Y[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stream (word, tag) pairs:\n",
      "\n",
      "\t ('Mr.', 'NOUN')\n",
      "\t ('Podger', 'NOUN')\n",
      "\t ('had', 'VERB')\n",
      "\t ('thanked', 'VERB')\n",
      "\t ('him', 'PRON')\n",
      "\t ('gravely', 'ADV')\n",
      "\t (',', '.')\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStream (word, tag) pairs:\\n\")\n",
    "for i, pair in enumerate(data.stream()):\n",
    "    print('\\t',pair)\n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Your emission counts look good!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pair_counts(sequences_A, sequences_B):\n",
    "    \"\"\"Return a dictionary keyed to each unique value in the first sequence list\n",
    "    that counts the number of occurrences of the corresponding value from the\n",
    "    second sequences list.\n",
    "    \n",
    "    For example, if sequences_A is tags and sequences_B is the corresponding\n",
    "    words, then if 1244 sequences contain the word \"time\" tagged as a NOUN, then\n",
    "    you should return a dictionary such that pair_counts[NOUN][time] == 1244\n",
    "    \"\"\"\n",
    "    pair_counts = {}\n",
    "    for i in range(0, len(sequences_A)):\n",
    "        for index, pair in enumerate(zip(sequences_A[i], sequences_B[i])):\n",
    "            if(pair[0] in pair_counts.keys()):\n",
    "                if pair[1] in pair_counts[pair[0]].keys():\n",
    "                    pair_counts[pair[0]][pair[1]] += 1\n",
    "                else:\n",
    "                    pair_counts[pair[0]][pair[1]] = 1\n",
    "                \n",
    "            else:\n",
    "                pair_counts[pair[0]] = {}\n",
    "                pair_counts[pair[0]][pair[1]] = 1\n",
    "    return pair_counts\n",
    "\n",
    "\n",
    "# Calculate C(t_i, w_i)\n",
    "emission_counts = pair_counts(data.Y, data.X)\n",
    "\n",
    "assert len(emission_counts) == 12, \\\n",
    "       \"Uh oh. There should be 12 tags in your dictionary.\"\n",
    "assert max(emission_counts[\"NOUN\"], key=emission_counts[\"NOUN\"].get) == 'time', \\\n",
    "       \"Hmmm...'time' is expected to be the most common NOUN.\"\n",
    "HTML('<div class=\"alert alert-block alert-success\">Your emission counts look good!</div>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Your MFC tagger has all the correct words!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a lookup table mfc_table where mfc_table[word] contains the tag label most frequently assigned to that word\n",
    "from collections import namedtuple\n",
    "\n",
    "FakeState = namedtuple(\"FakeState\", \"name\")\n",
    "\n",
    "class MFCTagger:\n",
    "    # NOTE: You should not need to modify this class or any of its methods\n",
    "    missing = FakeState(name=\"<MISSING>\")\n",
    "    \n",
    "    def __init__(self, table):\n",
    "        self.table = defaultdict(lambda: MFCTagger.missing)\n",
    "        self.table.update({word: FakeState(name=tag) for word, tag in table.items()})\n",
    "        \n",
    "    def viterbi(self, seq):\n",
    "        \"\"\"This method simplifies predictions by matching the Pomegranate viterbi() interface\"\"\"\n",
    "        return 0., list(enumerate([\"<start>\"] + [self.table[w] for w in seq] + [\"<end>\"]))\n",
    "\n",
    "\n",
    "# TODO: calculate the frequency of each tag being assigned to each word (hint: similar, but not\n",
    "# the same as the emission probabilities) and use it to fill the mfc_table\n",
    "\n",
    "word_counts = pair_counts(data.training_set.Y, data.training_set.X)\n",
    "\n",
    "mfc_table = {}\n",
    "for word in data.training_set.vocab:\n",
    "    count = -1\n",
    "    for key in word_counts.keys():\n",
    "        if(word in word_counts[key].keys()):\n",
    "            if word_counts[key][word] > count:\n",
    "                mfc_table[word] = key\n",
    "                count = word_counts[key][word]\n",
    "\n",
    "# DO NOT MODIFY BELOW THIS LINE\n",
    "mfc_model = MFCTagger(mfc_table) # Create a Most Frequent Class tagger instance\n",
    "\n",
    "assert len(mfc_table) == len(data.training_set.vocab), \"\"\n",
    "assert all(k in data.training_set.vocab for k in mfc_table.keys()), \"\"\n",
    "assert sum(int(k not in mfc_table) for k in data.testing_set.vocab) == 5521, \"\"\n",
    "HTML('<div class=\"alert alert-block alert-success\">Your MFC tagger has all the correct words!</div>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_unknown(sequence):\n",
    "    \"\"\"Return a copy of the input sequence where each unknown word is replaced\n",
    "    by the literal string value 'nan'. Pomegranate will ignore these values\n",
    "    during computation.\n",
    "    \"\"\"\n",
    "    return [w if w in data.training_set.vocab else 'nan' for w in sequence]\n",
    "\n",
    "def simplify_decoding(X, model):\n",
    "    \"\"\"X should be a 1-D sequence of observations for the model to predict\"\"\"\n",
    "    _, state_path = model.viterbi(replace_unknown(X))\n",
    "    return [state[1].name for state in state_path[1:-1]]  # do not show the start/end state predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Key: b100-28144\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.')\n",
      "\n",
      "\n",
      "Sentence Key: b100-23146\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.')\n",
      "\n",
      "\n",
      "Sentence Key: b100-35462\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['DET', 'ADJ', 'NOUN', 'VERB', 'VERB', 'VERB', 'ADP', 'DET', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'CONJ', 'ADP', 'DET', '<MISSING>', 'ADP', 'ADJ', 'ADJ', '.', 'ADJ', '.', 'CONJ', 'ADJ', 'NOUN', 'ADP', 'ADV', 'NOUN', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('DET', 'ADJ', 'NOUN', 'VERB', 'VERB', 'VERB', 'ADP', 'DET', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'CONJ', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', '.', 'ADJ', '.', 'CONJ', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'NOUN', '.')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in data.testing_set.keys[:3]:\n",
    "    print(\"Sentence Key: {}\\n\".format(key))\n",
    "    print(\"Predicted labels:\\n-----------------\")\n",
    "    print(simplify_decoding(data.sentences[key].words, mfc_model))\n",
    "    print()\n",
    "    print(\"Actual labels:\\n--------------\")\n",
    "    print(data.sentences[key].tags)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(X, Y, model):\n",
    "    \"\"\"Calculate the prediction accuracy by using the model to decode each sequence\n",
    "    in the input X and comparing the prediction with the true labels in Y.\n",
    "    \n",
    "    The X should be an array whose first dimension is the number of sentences to test,\n",
    "    and each element of the array should be an iterable of the words in the sequence.\n",
    "    The arrays X and Y should have the exact same shape.\n",
    "    \n",
    "    X = [(\"See\", \"Spot\", \"run\"), (\"Run\", \"Spot\", \"run\", \"fast\"), ...]\n",
    "    Y = [(), (), ...]\n",
    "    \"\"\"\n",
    "    correct = total_predictions = 0\n",
    "    for observations, actual_tags in zip(X, Y):\n",
    "        \n",
    "        # The model.viterbi call in simplify_decoding will return None if the HMM\n",
    "        # raises an error (for example, if a test sentence contains a word that\n",
    "        # is out of vocabulary for the training set). Any exception counts the\n",
    "        # full sentence as an error (which makes this a conservative estimate).\n",
    "        try:\n",
    "            most_likely_tags = simplify_decoding(observations, model)\n",
    "            correct += sum(p == t for p, t in zip(most_likely_tags, actual_tags))\n",
    "        except:\n",
    "            pass\n",
    "        total_predictions += len(observations)\n",
    "    return correct / total_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy mfc_model: 95.72%\n",
      "testing accuracy mfc_model: 93.02%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Your MFC tagger accuracy looks correct!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfc_training_acc = accuracy(data.training_set.X, data.training_set.Y, mfc_model)\n",
    "print(\"training accuracy mfc_model: {:.2f}%\".format(100 * mfc_training_acc))\n",
    "\n",
    "mfc_testing_acc = accuracy(data.testing_set.X, data.testing_set.Y, mfc_model)\n",
    "print(\"testing accuracy mfc_model: {:.2f}%\".format(100 * mfc_testing_acc))\n",
    "\n",
    "assert mfc_training_acc >= 0.955, \"Uh oh. Your MFC accuracy on the training set doesn't look right.\"\n",
    "assert mfc_testing_acc >= 0.925, \"Uh oh. Your MFC accuracy on the testing set doesn't look right.\"\n",
    "HTML('<div class=\"alert alert-block alert-success\">Your MFC tagger accuracy looks correct!</div>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
